{
    "name": "root",
    "gauges": {
        "Bedminton.Policy.Entropy.mean": {
            "value": 2.9087042808532715,
            "min": 2.90413761138916,
            "max": 3.758047342300415,
            "count": 152
        },
        "Bedminton.Policy.Entropy.sum": {
            "value": 58453.3203125,
            "min": 57803.95703125,
            "max": 75710.2890625,
            "count": 152
        },
        "Bedminton.Environment.EpisodeLength.mean": {
            "value": 10.197309417040358,
            "min": 9.471698113207546,
            "max": 10.27927927927928,
            "count": 152
        },
        "Bedminton.Environment.EpisodeLength.sum": {
            "value": 18192.0,
            "min": 18072.0,
            "max": 18256.0,
            "count": 152
        },
        "Bedminton.Self-play.ELO.mean": {
            "value": 816.3146237246868,
            "min": 569.4578562888279,
            "max": 2500.63229925392,
            "count": 152
        },
        "Bedminton.Self-play.ELO.sum": {
            "value": 728152.6443624207,
            "min": 521623.3963605663,
            "max": 2295380.5893777786,
            "count": 152
        },
        "Bedminton.Policy.ExtrinsicValueEstimate.mean": {
            "value": -1.0590314865112305,
            "min": -1.1714961528778076,
            "max": 0.9456050395965576,
            "count": 152
        },
        "Bedminton.Policy.ExtrinsicValueEstimate.sum": {
            "value": -945.715087890625,
            "min": -1095.348876953125,
            "max": 860.21484375,
            "count": 152
        },
        "Bedminton.Environment.CumulativeReward.mean": {
            "value": -1.0712354044364254,
            "min": -1.169573846589516,
            "max": 0.9543374211410356,
            "count": 152
        },
        "Bedminton.Environment.CumulativeReward.sum": {
            "value": -956.6132161617279,
            "min": -1105.3048251867294,
            "max": 875.8457577228546,
            "count": 152
        },
        "Bedminton.Policy.ExtrinsicReward.mean": {
            "value": -1.0712354044364254,
            "min": -1.169573846589516,
            "max": 0.9543374211410356,
            "count": 152
        },
        "Bedminton.Policy.ExtrinsicReward.sum": {
            "value": -956.6132161617279,
            "min": -1105.3048251867294,
            "max": 875.8457577228546,
            "count": 152
        },
        "Bedminton.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 152
        },
        "Bedminton.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 152
        },
        "Bedminton.Losses.PolicyLoss.mean": {
            "value": 0.017556281806901098,
            "min": 0.011265525322717925,
            "max": 0.024825850563744704,
            "count": 74
        },
        "Bedminton.Losses.PolicyLoss.sum": {
            "value": 0.017556281806901098,
            "min": 0.011265525322717925,
            "max": 0.024825850563744704,
            "count": 74
        },
        "Bedminton.Losses.ValueLoss.mean": {
            "value": 0.00937437101577719,
            "min": 0.00937437101577719,
            "max": 1.4702652176221211,
            "count": 74
        },
        "Bedminton.Losses.ValueLoss.sum": {
            "value": 0.00937437101577719,
            "min": 0.00937437101577719,
            "max": 1.4702652176221211,
            "count": 74
        },
        "Bedminton.Policy.LearningRate.mean": {
            "value": 0.0003,
            "min": 0.0003,
            "max": 0.0003,
            "count": 74
        },
        "Bedminton.Policy.LearningRate.sum": {
            "value": 0.0003,
            "min": 0.0003,
            "max": 0.0003,
            "count": 74
        },
        "Bedminton.Policy.Epsilon.mean": {
            "value": 0.20000000000000007,
            "min": 0.20000000000000007,
            "max": 0.20000000000000007,
            "count": 74
        },
        "Bedminton.Policy.Epsilon.sum": {
            "value": 0.20000000000000007,
            "min": 0.20000000000000007,
            "max": 0.20000000000000007,
            "count": 74
        },
        "Bedminton.Policy.Beta.mean": {
            "value": 0.008000000000000002,
            "min": 0.008000000000000002,
            "max": 0.008000000000000002,
            "count": 74
        },
        "Bedminton.Policy.Beta.sum": {
            "value": 0.008000000000000002,
            "min": 0.008000000000000002,
            "max": 0.008000000000000002,
            "count": 74
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1616745833",
        "python_version": "3.6.12 |Anaconda, Inc.| (default, Sep  9 2020, 00:29:25) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\91566\\anaconda3\\envs\\ml-agents\\Scripts\\mlagents-learn Bedminton.yaml --run-id=test2 --time-scale=100",
        "mlagents_version": "0.24.0",
        "mlagents_envs_version": "0.24.0",
        "communication_protocol_version": "1.4.0",
        "pytorch_version": "1.8.0",
        "numpy_version": "1.19.2",
        "end_time_seconds": "1616747472"
    },
    "total": 1639.4293774,
    "count": 1,
    "self": 0.005020500000000538,
    "children": {
        "run_training.setup": {
            "total": 0.2244775,
            "count": 1,
            "self": 0.2244775
        },
        "TrainerController.start_learning": {
            "total": 1639.1998794,
            "count": 1,
            "self": 2.0896698000224205,
            "children": {
                "TrainerController._reset_env": {
                    "total": 10.787839899999765,
                    "count": 8,
                    "self": 10.787839899999765
                },
                "TrainerController.advance": {
                    "total": 1626.161757499978,
                    "count": 97188,
                    "self": 1.996933999953626,
                    "children": {
                        "env_step": {
                            "total": 1189.0434231000131,
                            "count": 97188,
                            "self": 772.1538034000318,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 415.78723389997566,
                                    "count": 97188,
                                    "self": 7.22770939996343,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 408.55952450001223,
                                            "count": 95626,
                                            "self": 95.19533540002118,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 313.36418909999105,
                                                    "count": 95626,
                                                    "self": 313.36418909999105
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 1.102385800005674,
                                    "count": 97188,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 1629.544469400024,
                                            "count": 97188,
                                            "is_parallel": true,
                                            "self": 1017.6168125000011,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.00825350000005566,
                                                    "count": 16,
                                                    "is_parallel": true,
                                                    "self": 0.002522100000538291,
                                                    "children": {
                                                        "_process_vector_observation": {
                                                            "total": 0.00573139999951737,
                                                            "count": 32,
                                                            "is_parallel": true,
                                                            "self": 0.00573139999951737
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 611.9194034000228,
                                                    "count": 97188,
                                                    "is_parallel": true,
                                                    "self": 17.607466199962573,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 31.685064200008313,
                                                            "count": 97188,
                                                            "is_parallel": true,
                                                            "self": 31.685064200008313
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 501.34564490003027,
                                                            "count": 97188,
                                                            "is_parallel": true,
                                                            "self": 501.34564490003027
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 61.281228100021664,
                                                            "count": 194376,
                                                            "is_parallel": true,
                                                            "self": 19.939538600024235,
                                                            "children": {
                                                                "_process_vector_observation": {
                                                                    "total": 41.34168949999743,
                                                                    "count": 388752,
                                                                    "is_parallel": true,
                                                                    "self": 41.34168949999743
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 435.1214004000112,
                            "count": 97188,
                            "self": 14.219205899995359,
                            "children": {
                                "process_trajectory": {
                                    "total": 285.94243700001573,
                                    "count": 97188,
                                    "self": 285.50385960001574,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.4385773999999856,
                                            "count": 3,
                                            "self": 0.4385773999999856
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 134.95975750000014,
                                    "count": 74,
                                    "self": 89.07412200000522,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 45.88563549999492,
                                            "count": 2220,
                                            "self": 45.88563549999492
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 9.000000318337698e-07,
                    "count": 1,
                    "self": 9.000000318337698e-07
                },
                "TrainerController._save_models": {
                    "total": 0.16061130000002777,
                    "count": 1,
                    "self": 0.014839900000197304,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.14577139999983046,
                            "count": 1,
                            "self": 0.14577139999983046
                        }
                    }
                }
            }
        }
    }
}